{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2491748,"sourceType":"datasetVersion","datasetId":1500837}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ImageNet Transfer Learning Using ResNet50\n\n### Implemented by Pratham Shah, 240905614, for the Cryptonite Research Taskphase","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, Add, Dense, Flatten, GlobalAveragePooling2D, MaxPooling2D, Dropout, BatchNormalization, Activation\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications import EfficientNetV2S\nimport shutil\nfrom tensorflow.keras.metrics import TopKCategoricalAccuracy\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.optimizers import AdamW\nfrom tensorflow.keras.models import load_model\nfrom sklearn.calibration import label_binarize\nfrom sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef, auc, roc_curve, log_loss, accuracy_score, precision_score, f1_score, recall_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-24T12:48:05.467741Z","iopub.execute_input":"2025-06-24T12:48:05.468005Z","iopub.status.idle":"2025-06-24T12:48:09.232370Z","shell.execute_reply.started":"2025-06-24T12:48:05.467984Z","shell.execute_reply":"2025-06-24T12:48:09.231543Z"}},"outputs":[{"name":"stderr","text":"2025-06-24 12:48:06.044588: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750769286.066768     483 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750769286.073554     483 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Consolidating the 4 train subsets into 1","metadata":{}},{"cell_type":"code","source":"input_root = \"/kaggle/input/imagenet100\"\ntrain_output = \"/kaggle/working/imagenet100/train_combined\"\nval_path = \"/kaggle/input/imagenet100/val.X\" \n\nos.makedirs(train_output, exist_ok=True)\n\nfor i in range(1, 5):\n    subset_path = f\"{input_root}/train.X{i}\"\n\n    for class_name in os.listdir(subset_path):\n        src = f\"{subset_path}/{class_name}\"\n        dst = f\"{train_output}/{class_name}\"\n\n        if not os.path.exists(dst):\n            shutil.copytree(src, dst)\n            print(f\"Copied: {class_name} from train.X{i}\")\n        else:\n            print(f\"Skipped: {class_name} already exists\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T12:48:09.233801Z","iopub.execute_input":"2025-06-24T12:48:09.234268Z","iopub.status.idle":"2025-06-24T12:48:09.248974Z","shell.execute_reply.started":"2025-06-24T12:48:09.234248Z","shell.execute_reply":"2025-06-24T12:48:09.247937Z"}},"outputs":[{"name":"stdout","text":"Skipped: n01531178 already exists\nSkipped: n01440764 already exists\nSkipped: n01494475 already exists\nSkipped: n01950731 already exists\nSkipped: n01795545 already exists\nSkipped: n01632777 already exists\nSkipped: n02012849 already exists\nSkipped: n01775062 already exists\nSkipped: n02007558 already exists\nSkipped: n01484850 already exists\nSkipped: n01930112 already exists\nSkipped: n01984695 already exists\nSkipped: n02037110 already exists\nSkipped: n02018795 already exists\nSkipped: n01695060 already exists\nSkipped: n01978455 already exists\nSkipped: n01749939 already exists\nSkipped: n01824575 already exists\nSkipped: n01914609 already exists\nSkipped: n01833805 already exists\nSkipped: n01924916 already exists\nSkipped: n01665541 already exists\nSkipped: n01820546 already exists\nSkipped: n01687978 already exists\nSkipped: n01818515 already exists\nSkipped: n02058221 already exists\nSkipped: n01677366 already exists\nSkipped: n02077923 already exists\nSkipped: n01698640 already exists\nSkipped: n01592084 already exists\nSkipped: n01537544 already exists\nSkipped: n01514668 already exists\nSkipped: n01955084 already exists\nSkipped: n01773797 already exists\nSkipped: n01740131 already exists\nSkipped: n01735189 already exists\nSkipped: n01728572 already exists\nSkipped: n02027492 already exists\nSkipped: n01774384 already exists\nSkipped: n01443537 already exists\nSkipped: n01773549 already exists\nSkipped: n02018207 already exists\nSkipped: n01608432 already exists\nSkipped: n01770081 already exists\nSkipped: n01514859 already exists\nSkipped: n01729977 already exists\nSkipped: n02028035 already exists\nSkipped: n01843383 already exists\nSkipped: n01773157 already exists\nSkipped: n01753488 already exists\nSkipped: n01667114 already exists\nSkipped: n01582220 already exists\nSkipped: n01614925 already exists\nSkipped: n01664065 already exists\nSkipped: n01829413 already exists\nSkipped: n01498041 already exists\nSkipped: n01968897 already exists\nSkipped: n02011460 already exists\nSkipped: n01944390 already exists\nSkipped: n01560419 already exists\nSkipped: n01644900 already exists\nSkipped: n01756291 already exists\nSkipped: n02013706 already exists\nSkipped: n01847000 already exists\nSkipped: n01622779 already exists\nSkipped: n01751748 already exists\nSkipped: n02002556 already exists\nSkipped: n01685808 already exists\nSkipped: n01601694 already exists\nSkipped: n01734418 already exists\nSkipped: n01883070 already exists\nSkipped: n01693334 already exists\nSkipped: n02006656 already exists\nSkipped: n01828970 already exists\nSkipped: n01632458 already exists\nSkipped: n01985128 already exists\nSkipped: n01806143 already exists\nSkipped: n01774750 already exists\nSkipped: n01776313 already exists\nSkipped: n02051845 already exists\nSkipped: n01860187 already exists\nSkipped: n01855672 already exists\nSkipped: n01796340 already exists\nSkipped: n01667778 already exists\nSkipped: n01491361 already exists\nSkipped: n01729322 already exists\nSkipped: n01943899 already exists\nSkipped: n01978287 already exists\nSkipped: n01877812 already exists\nSkipped: n01675722 already exists\nSkipped: n01739381 already exists\nSkipped: n01742172 already exists\nSkipped: n01910747 already exists\nSkipped: n01798484 already exists\nSkipped: n01770393 already exists\nSkipped: n01630670 already exists\nSkipped: n01986214 already exists\nSkipped: n01819313 already exists\nSkipped: n01755581 already exists\nSkipped: n01496331 already exists\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Image Augmentation and Batch-wise generation","metadata":{}},{"cell_type":"code","source":"augmentor = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input,\n    rotation_range = 30,\n    zoom_range = 0.2,\n    shear_range = 0.1,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1\n)\n\ntrain_gen = augmentor.flow_from_directory(\"/kaggle/working/imagenet100/train_combined\", batch_size=32, target_size=(256, 256),)\nval_gen = augmentor.flow_from_directory(\"/kaggle/input/imagenet100/val.X\", batch_size=32, shuffle=False, target_size=(256, 256),)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T12:48:09.249962Z","iopub.execute_input":"2025-06-24T12:48:09.250432Z","iopub.status.idle":"2025-06-24T12:48:11.659127Z","shell.execute_reply.started":"2025-06-24T12:48:09.250396Z","shell.execute_reply":"2025-06-24T12:48:11.658578Z"}},"outputs":[{"name":"stdout","text":"Found 130000 images belonging to 100 classes.\nFound 5000 images belonging to 100 classes.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## The Model","metadata":{}},{"cell_type":"code","source":"base = EfficientNetV2S(input_shape=(256, 256, 3), include_top=False)\nbase.trainable = True\n\nmodel = Sequential([\n    base,\n    BatchNormalization(),\n    GlobalAveragePooling2D(),\n    \n    Dense(512, activation='relu', kernel_regularizer=l2(2e-4)),\n    BatchNormalization(),\n    Dropout(0.3),\n\n    Dense(256, activation='relu', kernel_regularizer=l2(2e-4)),\n    BatchNormalization(),\n    Dropout(0.3),\n\n    Dense(100, activation='softmax', kernel_regularizer=l2(2e-4))\n])\n\noptimiser = AdamW(learning_rate=2e-4, weight_decay=2e-5)\n\nmodel.compile(\n    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.15),\n    optimizer = optimiser,\n    metrics = [\"accuracy\", TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]\n)\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T12:48:11.660545Z","iopub.execute_input":"2025-06-24T12:48:11.660757Z","iopub.status.idle":"2025-06-24T12:48:15.329978Z","shell.execute_reply.started":"2025-06-24T12:48:11.660739Z","shell.execute_reply":"2025-06-24T12:48:15.329421Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1750769291.878592     483 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ efficientnetv2-s (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │      \u001b[38;5;34m20,331,360\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │           \u001b[38;5;34m5,120\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m655,872\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m25,700\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ efficientnetv2-s (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">20,331,360</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,152,452\u001b[0m (80.69 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,152,452</span> (80.69 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,994,484\u001b[0m (80.09 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,994,484</span> (80.09 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m157,968\u001b[0m (617.06 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">157,968</span> (617.06 KB)\n</pre>\n"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"early_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy', \n    patience=5,\n    restore_best_weights=True)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.5,\n    patience=3,\n    min_lr=1e-6,\n    verbose=1\n)\n\nsaver = ModelCheckpoint(\n    \"/kaggle/working/best_model.h5\",\n    monitor='val_accuracy',\n    save_best_only=True,\n    save_weights_only=False,\n    verbose=1\n)\n\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=12,\n    callbacks=[early_stop, reduce_lr, saver]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T12:48:15.330700Z","iopub.execute_input":"2025-06-24T12:48:15.330960Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/12\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1750769421.374829     547 service.cc:148] XLA service 0x7d40a40037c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1750769421.374877     547 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1750769432.527680     547 cuda_dnn.cc:529] Loaded cuDNN version 90300\nE0000 00:00:1750769448.958111     547 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750769449.155144     547 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750769449.638440     547 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750769449.846097     547 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750769450.415927     547 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750769450.642659     547 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nI0000 00:00:1750769488.820829     547 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2524/4063\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m13:15\u001b[0m 517ms/step - accuracy: 0.6899 - loss: 2.5256 - top_3_accuracy: 0.8067","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1750770815.617861     548 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750770815.808670     548 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750770816.250946     548 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750770816.451896     548 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750770816.991401     548 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1750770817.215955     548 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - accuracy: 0.7311 - loss: 2.3574 - top_3_accuracy: 0.8459\nEpoch 1: val_accuracy improved from -inf to 0.85120, saving model to /kaggle/working/best_model.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2515s\u001b[0m 572ms/step - accuracy: 0.7312 - loss: 2.3573 - top_3_accuracy: 0.8460 - val_accuracy: 0.8512 - val_loss: 1.7996 - val_top_3_accuracy: 0.9500 - learning_rate: 2.0000e-04\nEpoch 2/12\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - accuracy: 0.8633 - loss: 1.7778 - top_3_accuracy: 0.9586\nEpoch 2: val_accuracy improved from 0.85120 to 0.85560, saving model to /kaggle/working/best_model.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2251s\u001b[0m 554ms/step - accuracy: 0.8633 - loss: 1.7778 - top_3_accuracy: 0.9586 - val_accuracy: 0.8556 - val_loss: 1.7195 - val_top_3_accuracy: 0.9516 - learning_rate: 2.0000e-04\nEpoch 3/12\n\u001b[1m4019/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m23s\u001b[0m 524ms/step - accuracy: 0.8805 - loss: 1.6582 - top_3_accuracy: 0.9667\nEpoch 3: val_accuracy did not improve from 0.85560\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2215s\u001b[0m 545ms/step - accuracy: 0.8804 - loss: 1.6582 - top_3_accuracy: 0.9667 - val_accuracy: 0.8536 - val_loss: 1.6728 - val_top_3_accuracy: 0.9536 - learning_rate: 2.0000e-04\nEpoch 4/12\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526ms/step - accuracy: 0.8906 - loss: 1.5706 - top_3_accuracy: 0.9731\nEpoch 4: val_accuracy improved from 0.85560 to 0.85860, saving model to /kaggle/working/best_model.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2254s\u001b[0m 555ms/step - accuracy: 0.8906 - loss: 1.5706 - top_3_accuracy: 0.9731 - val_accuracy: 0.8586 - val_loss: 1.6240 - val_top_3_accuracy: 0.9538 - learning_rate: 2.0000e-04\nEpoch 5/12\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - accuracy: 0.9007 - loss: 1.5146 - top_3_accuracy: 0.9769\nEpoch 5: val_accuracy did not improve from 0.85860\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2245s\u001b[0m 552ms/step - accuracy: 0.9007 - loss: 1.5146 - top_3_accuracy: 0.9769 - val_accuracy: 0.8544 - val_loss: 1.6151 - val_top_3_accuracy: 0.9542 - learning_rate: 2.0000e-04\nEpoch 6/12\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529ms/step - accuracy: 0.9078 - loss: 1.4738 - top_3_accuracy: 0.9801\nEpoch 6: val_accuracy did not improve from 0.85860\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2463s\u001b[0m 606ms/step - accuracy: 0.9078 - loss: 1.4738 - top_3_accuracy: 0.9801 - val_accuracy: 0.8570 - val_loss: 1.5951 - val_top_3_accuracy: 0.9544 - learning_rate: 2.0000e-04\nEpoch 7/12\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - accuracy: 0.9149 - loss: 1.4407 - top_3_accuracy: 0.9814\nEpoch 7: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n\nEpoch 7: val_accuracy did not improve from 0.85860\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2217s\u001b[0m 546ms/step - accuracy: 0.9149 - loss: 1.4407 - top_3_accuracy: 0.9814 - val_accuracy: 0.8544 - val_loss: 1.6012 - val_top_3_accuracy: 0.9524 - learning_rate: 2.0000e-04\nEpoch 8/12\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - accuracy: 0.9347 - loss: 1.3703 - top_3_accuracy: 0.9889\nEpoch 8: val_accuracy improved from 0.85860 to 0.87260, saving model to /kaggle/working/best_model.h5\n\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2278s\u001b[0m 561ms/step - accuracy: 0.9347 - loss: 1.3703 - top_3_accuracy: 0.9889 - val_accuracy: 0.8726 - val_loss: 1.5477 - val_top_3_accuracy: 0.9598 - learning_rate: 1.0000e-04\nEpoch 9/12\n\u001b[1m 379/4063\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32:12\u001b[0m 525ms/step - accuracy: 0.9542 - loss: 1.3146 - top_3_accuracy: 0.9933","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Performance Monitoring","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tr = model.evaluate(train_gen)\nte = model.evaluate(val_gen)\npredictions = model.predict(val_gen)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for item in tr, te:\n    print(f\"Accuracy: {item[1]}\")\n    print(f\"loss: {item[0]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"example of the cnn output showing probabilities:\")\nprint(predictions[0])\n\nfinal = np.argmax(predictions, axis=1) #converts row into single value of highest prob. index = class ID\nreal_labels = real_labels = val_gen.classes\n\nindexed_items = list(val_gen.class_indices.keys())\n\nprint(classification_report(real_labels, final, target_names = indexed_items)) #classification report and confusion matrix\n\ncm = confusion_matrix(real_labels, final)\nsns.heatmap(cm, annot=True, fmt='d', cmap=\"inferno\")\nplt.title(\"Confusion matrix\")\nplt.xticks(np.arange(100) + 0.5, indexed_items, rotation=90)\nplt.yticks(np.arange(100) + 0.5, indexed_items, rotation=0)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,7))\nnp.fill_diagonal(cm, 0) #removing all correctly classified examples - in the diagonal\nsns.heatmap(cm, annot=True, cmap=\"coolwarm\")\nplt.xticks(np.arange(100) + 0.5, indexed_items, rotation=90)\nplt.yticks(np.arange(100) + 0.5, indexed_items, rotation=0)\nplt.title(\"Misclassification report\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filenames = val_gen.filenames\nerrors = np.where(final != real_labels)[0]\n\nfor i in errors[:5]:\n    # Load image using testing.directory + filenames[i]\n    img_path = os.path.join(val_gen.directory, filenames[i])\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(256, 256))\n    img_array = tf.keras.preprocessing.image.img_to_array(img).astype(\"uint8\")\n    \n    plt.imshow(img_array.astype(\"uint8\"))\n    plt.title(f\"True: {indexed_items[real_labels[i]]}, Pred: {indexed_items[final[i]]}\")\n    plt.axis(\"off\")\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Matthew's Correlation Coefficient : {matthews_corrcoef(real_labels, final)}\")\nprint(f\"Accuracy : {accuracy_score(real_labels, final)}\")\nprint(f\"f1 score : {f1_score(real_labels, final, average='weighted')}\")\nprint(f\"Log loss : {log_loss(real_labels, predictions)}\")\nprint(f\"Recall : {recall_score(real_labels, final, average='weighted')}\")\nprint(f\"Precision : {precision_score(real_labels, final, average='weighted')}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"real_bin = label_binarize(real_labels, classes=np.arange(100))\n\nplt.figure(figsize=(15, 10))\n\nfor i in range(100):\n    \n    false_p_rate, true_p_rate, thresholds = roc_curve(real_bin[:, i], predictions[:, i])\n    \n    roc_auc = auc(false_p_rate, true_p_rate) #higher area under curve - straighter the lines - lesser the FPR\n    \n    plt.plot(false_p_rate, true_p_rate, label=f\"{indexed_items[i]} - AUC: {roc_auc:.2f}\")\n\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curves (1 v/s rest)')\nplt.legend(loc='lower right')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}